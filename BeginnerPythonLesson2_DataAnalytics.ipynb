{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a Markdown code block\n",
    "\n",
    "### I'm still header text but I'm smaller.  Why is that?\n",
    "\n",
    "If you double click on me you will see that I am editable in a language called \"markdown\".  Search \"markdown syntax\" on google to find out how to use markdown language to make prettier visualizations.  Press \"shift+enter\" to make me pretty again.  You can decide whether a code block is \"Markdown\" or \"Python\" by changing the value of the dropdown box located at the top middle of the page.\n",
    "\n",
    "[Learn more about Jupyter Notebooks here](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## this is python code block  Remember that the pound sign \"#\" comments out code so that \n",
    "# the computer doesnt actually act on anything written on that line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this line with shift+enter\n",
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run me too\n",
    "print(\"hi everybody\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run me three\n",
    "for i in range(10):\n",
    "    print(\"hello: \" + str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Packages: Toolboxes that make life way way easier\n",
    "\n",
    "Think of each Python packages as a toolbox containing a bunch of tools (functions) meant for a specific task.  For example, if I was a plumber trying to replace a toilet, I would not bring the same tools to the job that I would for replacing my ceiling fan.  I keep those tools in seperate toolkits or partioned in seperate sections of my toolbox.\n",
    "\n",
    "Let's use **numpy** as an example of a python package.  **numpy** provides advanced mathematical formulas and vector-type transformations and calculations.  It will drag to the surface all of the repressed memories you have about when you took Linear Algebra.  **numpy** also happens to be a package that a significant number of other packages in Python are built on top of as vectors and linear algebra shows up in literally everything\n",
    "\n",
    "Steps for using Python packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As shown from our example above, importing packages is just importing code from other python files.  Nothing to crazy.  The value in packages is that downloading and managing them is quite simple (for the most part).  If you download a package, it goes to the same folder directory as the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.5  1.   1.5  2.   2.5  3.   3.5  4.   4.5  5.   5.5  6.   6.5  7.\n",
      "  7.5  8.   8.5  9.   9.5]\n"
     ]
    }
   ],
   "source": [
    "# load a package and all the functions and objects associated with that package\n",
    "import numpy\n",
    "\n",
    "# any functions you call from this package must be preceded by the name of the package\n",
    "\n",
    "print( numpy.arange(0.0,10.0,0.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.8  1.6  2.4  3.2  4.   4.8  5.6  6.4  7.2]\n"
     ]
    }
   ],
   "source": [
    "# you can load a specific function from a package and without using the package name as a header\n",
    "from numpy import arange\n",
    "\n",
    "print( arange(0.0,8.0,0.8) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.4  0.8  1.2  1.6  2.   2.4  2.8  3.2  3.6  4.   4.4  4.8  5.2  5.6\n",
      "  6.   6.4  6.8  7.2  7.6]\n"
     ]
    }
   ],
   "source": [
    "# you can give a nickname to the package when you import it\n",
    "import numpy as np\n",
    "\n",
    "print( np.arange(0.0,8.0,0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.   0.8  1.6  2.4  3.2  4.   4.8  5.6  6.4  7.2]\n"
     ]
    }
   ],
   "source": [
    "# you can load all the functions from a package without the header\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "print( arange(0.0,8.0,0.8) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does this package voodoo work?\n",
    "\n",
    "There is another file in your Python lesson 2 directory called \"**A_Different_Python_File_In_The_Same_Directory.py**\"  Let's import all of the functions from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from A_Different_Python_File_In_The_Same_Directory import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello you squirrelly bunch you!\n"
     ]
    }
   ],
   "source": [
    "# We haven't declared this function yet.  Why does it work?\n",
    "\n",
    "helloVanguardPythonStudents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown from our example above, importing packages is just importing code from other python files.  Nothing too crazy.  The value in packages is that downloading and managing them is quite simple (for the most part).  If you download a package, it goes to the same folder directory as all your other packages and Python knows to look in that directory for those packages.\n",
    "\n",
    "**Note: This next part only works on a vanguard computer if you have the paid version of anaconda**\n",
    "\n",
    "sys - native Python package that lets you access systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\python36.zip',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\DLLs',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib\\\\site-packages\\\\Sphinx-1.5.6-py3.6.egg',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib\\\\site-packages\\\\setuptools-27.2.0-py3.6.egg',\n",
       " 'C:\\\\Progra~1\\\\Anaconda3_4\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\uwal\\\\.ipython']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching package metadata ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaHTTPError: HTTP None None for url <https://anaconda-repo.opsp.c1.vanguard.com/conda/anaconda/win-64/repodata.json>\n",
      "Elapsed: None\n",
      "\n",
      "An HTTP error occurred when trying to retrieve this URL.\n",
      "HTTP errors are often intermittent, and a simple retry will get you on your way.\n",
      "ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='anaconda-repo.opsp.c1.vanguard.com', port=443): Max retries exceeded with url: /conda/anaconda/win-64/repodata.json (Caused by NewConnectionError('<requests.packages.urllib3.connection.VerifiedHTTPSConnection object at 0x0000011B4FAE7780>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed',))\",),)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download new packages:\n",
    "\n",
    "# use ! (exclamation point) which tells jupyter to act as if it was command line\n",
    "\n",
    "# to download a package you need, type: conda install <packageName> -y\n",
    "\n",
    "# the \"-y\" just tells the installation to preemptively say yes to any questions\n",
    "\n",
    "! conda install pandas -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://cdn-images-1.medium.com/max/1600/1*OpxJXlkjvcCuhkYYlPwTjA.png)\n",
    "\n",
    "#### To find out which directories/folders python looks in to find other packages, you can look at the system path for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Progra~1\\Anaconda3_4\\python36.zip\n",
      "C:\\Progra~1\\Anaconda3_4\\DLLs\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\n",
      "C:\\Progra~1\\Anaconda3_4\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\\site-packages\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\\site-packages\\Sphinx-1.5.6-py3.6.egg\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\\site-packages\\win32\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\\site-packages\\win32\\lib\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\\site-packages\\Pythonwin\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\\site-packages\\setuptools-27.2.0-py3.6.egg\n",
      "C:\\Progra~1\\Anaconda3_4\\lib\\site-packages\\IPython\\extensions\n",
      "C:\\Users\\uwal\\.ipython\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "for folder in sys.path:\n",
    "    print(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create a basic graph Example\n",
    "\n",
    "Below is code that visualizes the the sin wave.  Notice how the code loads certain packages (\"NumPy\" for create numerical data vectors quickly, and \"Matplotlib\" for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          1.06279052  1.12533323  1.18738131  1.24868989  1.30901699\n",
      "  1.36812455  1.42577929  1.48175367  1.53582679]\n"
     ]
    }
   ],
   "source": [
    "# notice how we load python packages \n",
    "import matplotlib.pyplot  # a subgroup of functions with a package\n",
    "import numpy\n",
    "\n",
    "# notice how we call functions from the numpy package\n",
    "time = numpy.arange(0.0, 2.0, 0.01)  \n",
    "sinWave = 1 + numpy.sin(2 * numpy.pi * time)\n",
    "print(sinWave[:10])\n",
    "\n",
    "# run me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin Wave???? No one said anything about Trigonometry :( \n",
    "\n",
    "### Now lets graph the sinWave through time by using the package 'matplotlib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matplotlib.pyplot.plot(time, sinWave)\n",
    "\n",
    "matplotlib.pyplot.xlabel('time (s)')\n",
    "matplotlib.pyplot.ylabel('voltage (mV)')\n",
    "\n",
    "matplotlib.pyplot.title('Wave Function Graph')\n",
    "matplotlib.pyplot.grid(True)\n",
    "\n",
    "matplotlib.pyplot.savefig(\"I_wasnt_here_before_picture.png\")\n",
    "\n",
    "matplotlib.pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE POWER OF PYTHON PACKAGES!\n",
    "![alt text](https://imgs.xkcd.com/comics/python.png)\n",
    "\n",
    "\n",
    "1. With **NumPy** we can create vectors for matrix functions like vector multiplication\n",
    "\n",
    "2. With **MatPlotLib** we can quickly create visualizations with even just 6 lines of code!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for the Pandas Python Package\n",
    "<img src=\"http://geospatialtraining.com/wp-content/uploads/2018/01/Tutorial.png\" width=600px>\n",
    "\n",
    "\n",
    "Pandas is one of the backbone data analytics libraries for Python as it combines several packages and then adds on top of them for easy use.  Those packages include:\n",
    "\n",
    "1. Built on top of NumPy and so can perform Linear Algebra type manipulations on lists while retaining the NumPy speed boost.\n",
    "2. Represents data as columns and rows for easier visualizing and understanding of the data.\n",
    "3. Built on top of the StatsModels package and so useful statistical functions like finding the **correlation** or **percent change** between lists of data extremely easy to do.\n",
    "4. Can query data from the internet, SQL databases, Excel files, CSV files, in one line commands\n",
    "5. Portions of the MatPlotLib visualization library are built into Pandas.\n",
    "6. Includes SQL and Excel-type data manipulations \n",
    "\n",
    "## Now lets get our hands dirty with some Pandas data analytics\n",
    "\n",
    "1. Load the pandas package into your python environment\n",
    "2. Load the csv file \"**DomainCount.csv**\"\n",
    "\n",
    "[Find help here!  Seriously, click this link!](https://chrisalbon.com/python/data_wrangling/pandas_dataframe_importing_csv/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the \"pandas\" package here\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a pandas dataframe variable called \"internetSheet\" and load the csv file into it\n",
    "\n",
    "internetSheet = pandas.\n",
    "\n",
    "# don't touch the below line\n",
    "internetSheet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Selecting and Indexing of Rows and Columns\n",
    "\n",
    "#### [Pandas Cheat Sheet Reference Page: Click Me!](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)\n",
    "\n",
    "DataFrame  (example shorthand variable name: \"df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DataFrame data type\n",
    "type(internetSheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first five rows\n",
    "internetSheet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#last five rows\n",
    "internetSheet.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two methods of selecting columns:\n",
    "\n",
    "- square braces + quotes:  **df['< name of column >']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "internetSheet['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using dot (period) notation:  **df.< column name>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "internetSheet.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# columns are data type series:\n",
    "type(internetSheet['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## select multiple columns:nested square brackets\n",
    "\n",
    "internetSheet[['url','pageViews']].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select rows by position\n",
    "\n",
    "# all values in second column\n",
    "internetSheet.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all column values in first row\n",
    "internetSheet.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last column of last row\n",
    "internetSheet.iloc[-1,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting a subset of data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all rows with pageViews less than 30\n",
    "\n",
    "internetSheet[ internetSheet['pageViews'] < 30 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Excel sheet contains URL's a person has visited.  Lets find out which domain, twitter.com or IMDB.com, Christian visited the most.\n",
    "\n",
    "### Domains are the sections of the URL before the firstslash \"/\" so lets split the string into a list of strings seperated by backslashes\n",
    "\n",
    "**twitter.com/login** --> [\"**twitter.com**\", \"**login**\"]\n",
    "\n",
    "Answer is found here -> https://pandas.pydata.org/pandas-docs/stable/text.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ex:  internetSheet['url']\n",
    "\n",
    "# Let's create a new column called 'url list' and have it hold the string split list of values\n",
    "\n",
    "\n",
    "internetSheet['url list'] = \n",
    "\n",
    "\n",
    "# don't touch the below line\n",
    "internetSheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From that url list column, extract the first index in each list and move it to a new column \"domain\"\n",
    "\n",
    "#### Hey that list comprehension from last time might be helpful to remember here\n",
    "\n",
    "Answer is found in the same webpage yoou just visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets create a new column called \"domain\" that contains the first value of every list from \n",
    "# the column \"url list\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# don't touch the below line\n",
    "internetSheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now group the rows by domain and sum the page views to see which website the user visited more\n",
    "\n",
    "Create a new pandas dataframe variable called \"domain\" that is the shows the aggregation pageViews by domain.  This is similar to \"group by\" in R and Pivot Tables in Excel\n",
    "\n",
    "(https://stackoverflow.com/questions/32751229/pandas-sum-by-groupby-but-exclude-certain-columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "domains = \n",
    "\n",
    "\n",
    "# don't touch the below line\n",
    "domains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats! you just did some basic data analysis in Python and Pandas\n",
    "You learned how to:\n",
    "1. string cleaning to get the domain out of a url\n",
    "2. load python packages\n",
    "3. Load a csv file as a pandas dataframe\n",
    "4. how to create new dataframe columns\n",
    "5. how to group by and aggregate columns and row for analysis\n",
    "\n",
    "\n",
    "## Let us move onto some more in-depth analysis and observe what is known as the Simpson Paradox\n",
    "\n",
    "Sadly not related to the Simpsons\n",
    "\n",
    "![alt text](data:image/png;base64,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)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: NYU fears it is discriminating against Sharks in favor of Jets in the college application process.  \n",
    "\n",
    "## Lets analyze to see if that is the case.\n",
    "1. Create a pandas DataFrame called \"simpsons\" loaded from the \"excel\" file \"**simpsons.xlsx**\"\n",
    "2. Create a groupby DataFrame called \"general\" that aggregates the groupings of \"**Admit**\", and \"**Group**\" in order to find the acceptance rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a pandas DataFrame called \"simpsons\" loaded from the \"excel\" file \"simpsons.xlsx\"\n",
    "\n",
    "simpsons = \n",
    "\n",
    "# don't edit below\n",
    "simpsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a groupby dataframe called general from simpsons.  We will be grouping from two columns\n",
    "# instead of one.  The code will be very similar to the last grouping\n",
    "\n",
    "\n",
    "# don't edit below\n",
    "general = pandas.DataFrame(general)  #groupby results don't actually create new dataframes so we need to do it again\n",
    "general = general.reset_index() # this dataframe had tiered indexes/indices (columns) which we didn't want\n",
    "general"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that \"Admitted\" and \"Rejected\" are row values.  We want to make them column values instead so that we can find the acceptance rate.  This is similar to pivot tables in excel.\n",
    "\n",
    "Answer is here -> https://stackoverflow.com/questions/28337117/how-to-pivot-a-dataframe-in-pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pivot =\n",
    "\n",
    "#don't edit below\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets create a column called acceptance rate.  You can look earlier on this sheet for how to create columns\n",
    "\n",
    "#### Go back to the previous Twitter vs IMDB example for declaring new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#don't edit below\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeez, It looks like Jets are definitely favored over Sharks.  It doesn't take a statistical test to see that.  However, before we start posting our pseudo science results on Twitter, we should check and see how that discrimination breaks down by department\n",
    "\n",
    "In this case let us create a dataframe called \"**dept**\" that is a pivot table of \"**simpsons**\" based off both group and department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check back on your previous pivot table and change it to reflect that you are grouping\n",
    "# by two columns instead of 1\n",
    "\n",
    "dept = \n",
    "\n",
    "# don't edit below\n",
    "dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To flatten the index so that we have access to everything, we will reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dept = dept.reset_index()\n",
    "\n",
    "dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a column \"**acceptance rate**\" like we did before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# don't edit below\n",
    "dept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets filter to find out which Group has the highest acceptance rate in each department\n",
    "\n",
    "Answer is here -> https://stackoverflow.com/questions/25071937/filter-pandas-dataframe-based-on-max-values-in-a-column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# google search: \"filter based on highest value in  pandas\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the above outputs with our original results from general_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run me\n",
    "pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the acceptance rates of the different departments, what is the data telling us now?\n",
    "\n",
    "What did we learn?\n",
    "1. Never trust data\n",
    "2. How to use pivot tables\n",
    "3. Loading excel files\n",
    "\n",
    "\n",
    "![alt text](https://lh3.googleusercontent.com/-9HNmhBkcK8I/WIgR1skepYI/AAAAAAAAizU/ZwUg-1jWBhU/s640/blogger-image--1454242550.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Exercise:  Filtering Weekends and Holidays from a dataset\n",
    "Dealing with timestamps in data analysis is terrible for many reasons:\n",
    "1. Dates are written as strings so you can't add or subtract them\n",
    "2. Excel usually converts some dates but not others and creates a mess\n",
    "3. Dealing with timezones\n",
    "4. Finding out weekdays and business days\n",
    "\n",
    "Python has this handy package called \"**datetime**\" that makes dealing with dates much easier. Lets load up an excel file and see this in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime  # we won't use this because its also built into pandas but you should know its a seperate package\n",
    "dates = pd.read_excel(\"dateWorkbook.xlsx\")\n",
    "dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so some dingbat decided to record the dates using spaces, dashes, and the proper full names of the months. Ugh how rude.  But we are in python so we can fix this rather easily because, as long as you specify the format of the date string, Python will turn any string into a datetime object.  To find the symbols referencing different types of date representations, visit http://strftime.org.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates['date'] = pd.to_datetime(dates['evilDateFormat'], format= \"%Y %B-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dates.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OH SNAP! \n",
    "In one line of code we converted an evil date string into something actually usable!  Pandas has a whole bunch of other packages built into it.  What other magic can it do?  \n",
    "### Can it Find Weekdays???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First lets set 'date' to be the index Pandas dataframe index\n",
    "# An index in a database is a column where every value has to be unique\n",
    "# no two rows can have the same index value\n",
    "\n",
    "# Index = Primary Key.  For all you SQL lovers out there\n",
    "\n",
    "dates.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now lets find out which dates land on a weekday.  \n",
    "dates['weekday'] = dates.index.weekday\n",
    "\n",
    "dates.tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets remove all Saturday and Sunday entries\n",
    "Monday is represented with 0 and Sunday is 6 so we want to remove all 5's and 6's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weekdays = dates[dates['weekday'] < 5]\n",
    "weekdays.tail(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That's cool and all.. but how do we get rid of holidays????? Yeah Pandas has a solution for that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the USFederalHolidays calendar from pandas, add Good Friday and remove Veteran's and Columbus days\n",
    "\n",
    "from pandas.tseries.holiday import get_calendar, HolidayCalendarFactory, GoodFriday\n",
    "from datetime import datetime\n",
    "\n",
    "cal = get_calendar('USFederalHolidayCalendar')  # Create calendar instance\n",
    "\n",
    "# There are 9 financial holidays but 10 US federal Holidays.\n",
    "# Financial holidays include Good Friday\n",
    "if len(cal.rules) == 10:\n",
    "    cal.rules.pop(7)                                # Remove Veteran's Day rule\n",
    "    cal.rules.pop(6)                                # Remove Columbus Day rule\n",
    "tradingCal = HolidayCalendarFactory('TradingCalendar', cal, GoodFriday)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see which holidays **tradingCal** has with by checking its **.rules** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for holiday in tradingCal.rules:\n",
    "    print(holiday.name)\n",
    "print(\"\\nNumber of Holidays: %s\" % len(tradingCal.rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holidays = tradingCal.holidays(tradingCal,start='2012-11-01',end='2018-12-30')\n",
    "#weekdays['holiday'] = [\"Biz\" if x not in tradingCal.holidays(tradingCal) else \"Holiday\" for x in weekdays['date']]\n",
    "\n",
    "print(holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we can filter for all the rows with index values NOT in that list.  In pandas, the \"NOT\" symbol is denoted by the tilde '~' **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "businessdays = weekdays[~weekdays.index.isin(holidays)]\n",
    "businessdays.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### November 23rd was Thanksgiving and I don't see it up there!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the number of business days between two values by subtracting the row value of the start date from the row value of the end date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_date = '11-21-2017'\n",
    "end_date = '11-27-2017'\n",
    "\n",
    "num_days = businessdays.index.get_loc(end_date) - businessdays.index.get_loc(start_date)\n",
    "print(\"Number of business days between \"+start_date+\" and \"+end_date+\" is: %s\" % num_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](https://i.pinimg.com/736x/6c/28/6f/6c286f8786ca890a9d61e2543d9a5b0d--computer-science-humor-computer-jokes.jpg)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your turn!  There is a second tab in dateWorkbook.xlsx.  Repeat the exercise above and follow the directions below\n",
    "\n",
    "1. Load in the second tab of the excel file\n",
    "2. convert the weird format (Month Year Day) into something usable\n",
    "3. remove weekdays\n",
    "4. sum the remaining PageViews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I'm gonna need you to google this part\n",
    "exercise = \n",
    "\n",
    "\n",
    "######## can't touch this\n",
    "exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a column with the datetime conversions\n",
    "# Visit this website for guidance:  \n",
    "# https://docs.python.org/3.1/library/datetime.html#strftime-strptime-behavior\n",
    "\n",
    "exercise['dates'] = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filter for only weekdays\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Exercise: SQL Table Joins / V-lookups in Pandas.  \n",
    "Just like in SQL and excel (with V-lookups), you can do table joins in pandas order to connect two different datasets (tables) by a shared column/primary key\n",
    "\n",
    "In this example, we will be importing the excel file **\"musicWorkbook.xlsx\"** which has two tabs.  One tab has the current top 25 Billboard songs and their artists.  The second tab has a list of artists and their respective genres.  In this exercise we will be trying to find the genre most represented in the Billboard top 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the first tab of the excel file into a dataframe called 'songs'\n",
    "# you will need to learn how specify which tab to load into \n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the second tab of the excel file into a dataframe called 'artists'\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have **songs** and **artists** dataframes, let us join them to create a 3rd dataframe called \"**combined**\".\n",
    "\n",
    "Answer is here -> https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# HERE -> https://pandas.pydata.org/pandas-docs/stable/merging.html#database-style-dataframe-joining-merging\n",
    "# You want to look for some function that is either \".merge\" or \".join\"\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now lets group and sum \"combined\" into a variable called genre in order to find \n",
    "# the genre that is most represented.\n",
    "# we did this before so look further up the page for a refresher\n",
    "\n",
    "\n",
    "\n",
    "####################\n",
    "genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS ROUND!  PANDAS + SQL\n",
    "There is a python package (of course there is) that enables you to interact with pandas dataframes like they were SQL tables.  Just in case you didn't want to learn all of the pandas syntax!\n",
    "\n",
    "*This only works if you have the enterprise licence for Python.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sqlExample = pd.read_excel(\"dateWorkbook.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look at all the variables we have so far for something names sqlExample and query it\n",
    "sqldf(\"select * from sqlExample where pageViews > 30\", locals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now you can do all sorts of fun data analysis.  If you want to learn more, log on to pluralsight with a vanguard account and access the 4 free data camp courses.  DataCamp will also soon be available to non\n",
    "\n",
    "If you are in IT, this should be an MCA role you can grab.  IF you are outside IT, I believe you need special permission and there is a charge.\n",
    "\n",
    "You can also reach me, Christian Rivera, at christian_rivera@vangaurd.com for any questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
